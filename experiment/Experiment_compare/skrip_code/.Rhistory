# Copyright 2017, Andrey Skripnikov, All rights reserved.
#setwd("/home/usdandres/Downloads/Revision/")
source("./function.R")
set.seed(2)
###########
## Code for simulated experiment:
## comparing joint and separate approaches for estimating TWO simulated Granger networks.
## (code needs some adjustments for higher number K of networks)
##
## Here is the layout of the code:
##   1. User-defined parameters(all variable descriptions are given next to parameters)
##   2. Data generation(both stationary transition matrices,
##                      both error covariance matrices that follow K-factor model,
##                      both simulated time series following the VAR model)
##   3. Separate estimation.
##   4. Joint estimation.
##   5. Printing all the results(details of each performance measure are given
##                               in the end)
##
## Separate estimation is done in Simul.Data.Separate.Main() function
## that takes no arguments but uses global variables.
## Summary of what it does:
##     - initializes both error covariance matrices with identities,
##     - estimates transition matrix for each entity separately via l1-estimation
##   and AIC criterion for tuning parameter selection,
##     - uses the transition matrix estimates to get residuals,
##     - use residuals as data to estimate error inverse covariance matrices
##   with help of L-factor model and graphical lasso separately,
##     - plug-in the resulting inverse error covariance estimates and re-estimate
##   transition matrices separately for each entity via l1-estimation and AIC
##   criterion for tuning parameter selection,
##   For more details on the code - see Paper.functions.R
##
## Joint estimation is done in Simul.Data.Joint.Main() function
## that takes no arguments but uses global variables.
##
## Summary of what it does:
##     - uses the estimates of inverse error covariances from the separate estimation process
##       (just plugs them in)
##     - combines both entites into one standardized dataset, sets up the generalized
##       fused lasso as discussed in paper with two tuning parameters lambda1 and lambda2
##     - does sequential search of tuning parameter values: fix lambda2, grid search for lambda1.est,
##       fix lambda1=lambda1.est, grid search for lambda2.est, fix lambda2=lambda2.est etc etc
##     - criterion used for search: AIC distinct(described in Paper.functions.R)
##     - the fusion of parameters is done with help of ADMM algorithm, described
##       in detail in the paper and in Paper.functions.R,
##     - refitting the estimate using the structure(skeleton) of the original
##     estimate: get rid of columns of data matrix(that COMBINES entities)
##     that correspond to zero elements in the original estimate,
##     fit a regression with a tiny sparsity penalty
##     (to shrink elements a little bit, but so that none of them are 0)
## For more details on how the code functions work see Paper.function.R.
########################################
####  USER-DEFINED PARAMETERS         ##
########################################
### General parameters
K <- 3                     # number of entities
p <- 10                     # number of variables per entity
train <- 30                  # number of training points per entity
rep <- 1                       # Number of replicates
skip <- 0                       # For code reproducibility: in case I'd like to rerun 50 replicates for the same seed,
# but running them in a single program would take too long, and I have to break it into chunks of 5-10 replicates.
max_eig <- 0.6            # max eigenvalue of VAR transition matrices
diff = TRUE               # whether to generate same or different matrices for two entities
h <- 1                      # h-step forecasts will be made
test <- train + 1:h         # test time points(to measure forecasting precision) per entity
t <- train + h              # total number of time points per entity
SNR <- 2                    # Signal-to-Noise ratio
L <- 2                     # number of factors for the L-factor model per entity
sigma.iter <- 2           # number of iterations for error covariance estimation procedure
ed <- 0.04               # off-diagonal edge density shared for both entities
comm <- 0.02               # off-diagonal edge density specific for each entity
Results <- matrix(0,rep,10) # performance measures put into one vector:
# Pred.Err.Joint, FP.Joint, FN.Joint, Matt.Coef.Joint,
# Frob.Joint, Pred.Err.Sep, FP.Sep, FN.Sep,
# Matt.Coef.Sep, Frob.Sep
Results.General <- matrix(0,rep,6) # performance measures put into one vector:
#### criterions for tuning parameter selection
criter.joint.1 <- "AICc"  # criterion to select sparsity parameter for joint estimates
criter.joint.2 <- "BIC.dist" # criterion to select fusion parameter for joint estimates
criter.sep <- "AICc"       # criterion to select sparsity parameter for separate estimates
df.sep <- 2                     # the multiplier for "degrees of freedom" part of the criterion for SEPARATE
### parameters for glmnet() function performing solution path calculation for standard lasso problem
fail <- 0
fail.thresh <- 0.7
intercept <- FALSE
standardize <- TRUE
### ADMM algorithm parameters ###
rho <- 10                   # ADMM rho penalty parameter
init <- "0"                 # initialize ADMM with Identity("1"),Zero-matrix("0"), or with separate estimates
eps <- 0.001           # stopping criterion
iter.thresh <- 200     # max number of iterations per one run of ADMM algorithm
fused.thresh <- 0.01  # threshold for differences between elements
n.iter <- 1            # number of sequential iterations
### lambda grid parameters
knots1 <- 15                                           # controls lower bound of lambda1 path
knots2 <- 20                                           # controls lower bound of lambda2 path
L1 <- NULL                                              # length of lambda1 grid(NULL means we calculate lambda1 path automatically)
L2 <- 20                                                # length of lambda2 grid
#lambda.path <- 1*(1/2)^seq(0, knots1, length = L1)     # lambda1 grid
#L1 <- length(lambda.path)
lambda2.path <- c((2*p)*rho*(1/2)^seq(0, knots1, length = L2),0)   # lambda2 grid, making sure we capture the whole specter of fusion:
# from identical A11=A22(for high values of lambda2) to dissimilar A11 and A22(low values of lambda2)
L2 <- length(lambda2.path)
### Thresholding parameters
ConstThresh <- TRUE         # whether to use the hard threshold for final estimates
Thresh <- 0.1               # the value of hard threshold for the final estimate
#criter.sep <- "AIC"        # the criterion to use for tuning parameter selection
df <- 2                     # for AIC.dist
################################################
## Printing out all the main parameter values ##
################################################
print(c("p:",p))
print(c("t:",t))
print(c("Init:",init))
print(c("criter.joint.1:",criter.joint.1))
print(c("criter.joint.2:",criter.joint.2))
print(c("criter.sep:",criter.sep))
print(c("df.sep",df.sep))
print(c("rho:",rho))
print(c("fail.thresh=",fail.thresh))
print(c("L:",L))
print(c("SNR:",SNR))
print(c("diff:",diff))
print(c("rep",rep))
print(c("skip",skip))
print(c("ConstThresh",ConstThresh))
print(c("Thresh",Thresh))
print(c("l_lambda1.path",L1))
#print(c("lambda1:",lambda.path))
print(c("lambda2:",lambda2.path))
print(c("eps:",eps))
print(c("iter.thresh",iter.thresh))
print(c("ed:",ed))
print(c("comm:",comm))
print(c("max_eig:",max_eig))
print(c("n.iter:",n.iter))
setwd("~/Documents/JGranger_ncvx/experiment/Experiment_compare/skrip_code")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
warnings()
ncol_X
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
for (iterates in 1:length(first_index_list)){
first_idx = first_index_list[iterates]
second_idx = second_index_list[iterates]
# print(c(first_idx,second_idx))
fus.shrink <- ifelse(abs(beta.next[(first_idx-1)*group_size+1:first_idx*group_size] - beta.next[(second_idx-1)*group_size+1:second_idx*group_size])<fus.thresh,1,0)
# tmp = beta.next
beta.next.avg <- sparsify((beta.next[(first_idx-1)*group_size+1:first_idx*group_size] + beta.next[(second_idx-1)*group_size+1:second_idx*group_size])/2,fus.thresh) # this line computes
print(("beta.next.avg"))
print(length(beta.next.avg))
print(("beta.next mini chunk"))
print(length(beta.next[(first_idx-1)*group_size+1:first_idx*group_size]))
beta.next[(first_idx-1)*group_size+1:first_idx*group_size] <- fus.shrink*beta.next.avg + (1-fus.shrink)*beta.next[(first_idx-1)*group_size+1:first_idx*group_size]
beta.next[(second_idx-1)*group_size+1:second_idx*group_size] <- fus.shrink*beta.next.avg + (1-fus.shrink)*beta.next[(second_idx-1)*group_size+1:second_idx*group_size]
sum.shrunk[ind] <- sum.shrunk[ind] + sum(beta.next[(first_idx-1)*group_size+1:first_idx*group_size]  == beta.next[(second_idx-1)*group_size+1:second_idx*group_size])
}
beta.next
beta.next[(first_idx-1)*group_size+1:first_idx*group_size]
beta.next[(1-1)*group_size+1:1*group_size]
group_size
beta.next[(1-1)*group_size+1:1*group_size,]
beta.next[,(1-1)*group_size+1:1*group_size]
beta.next[1:3]
1*group_size
beta.next[1:25]
(1-1)*group_size+1:1*group_size
((1-1)*group_size+1):(1*group_size)
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
u.next
u.est
length(u.est)
length(u.est[1])
length(u.est[2])
length(u.est[[1]])
dim(u.est)
37*81
source("skrip_main.R")
source("skrip_main.R")
beta.next
sum.shrunk
first_index_list
second_index_list
iterates
fus.shrink
beta.next[((first_idx-1)*group_size+1):(first_idx*group_size)]
group_size
K
ncol_X
source("skrip_main.R")
source("skrip_main.R")
ncol_X
(2*25+1):(3*25)
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
obj.est
obj.next
u.next
beta.next
source("skrip_main.R")
source("skrip_main.R")
length(beta.next)
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
u.next
u.est
dim(u.est)
source("skrip_main.R")
source("skrip_main.R")
dim(u.est)
u.prev
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
setwd("~/Documents/JGranger_ncvx/experiment/Experiment_compare/skrip_code")
source("skrip_main.R")
All
All.object
Joint.Est
Joint.Est.Obj
source("skrip_main.R")
setwd("~/Documents/JGranger_ncvx/experiment/Experiment_compare/skrip_code")
source("skrip_main.R")
source("skrip_main.R")
20*20*5
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
source("skrip_main.R")
first_index_list
second_index_list
group_size
u.est
dim(u.est)
dim(u.next)
ncol_X
dim(Lm.b)
dim(beta.next)
dim(Lm)
source("skrip_main.R")
source("skrip_main.R")
2!
nchoosek(5,2)
nChooseK(5,2)
factorial(5)/(factorial(5-2)factorial(2))
factorial(5)/(factorial(5-2)*factorial(2))
source("skrip_main.R")
source("skrip_main.R")
